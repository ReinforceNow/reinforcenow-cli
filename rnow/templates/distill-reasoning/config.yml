project_id: ""
project_name: "distill-reasoning"
dataset_id: ""
dataset_name: "train"
dataset_type: distill
organization_id: ""
data:
  train_file: train.jsonl
  batch_size: 8
  group_size: 4
model:
  path: Qwen/Qwen3-8B
  qlora_rank: 32
  name: "Distilled Reasoning Model"
  description: "8B model distilled from larger teacher"
teacher:
  path: Qwen/Qwen3-32B
rollout:
  max_turns: 1
  max_tokens: 8192
trainer:
  num_epochs: 3
  learning_rate: 0.0001
  save_step: 20
