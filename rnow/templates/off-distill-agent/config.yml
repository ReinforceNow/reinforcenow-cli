project_id: ""
project_name: "off-distill-agent"
dataset_type: sft  # Supervised fine-tuning on teacher-generated data

data:
  train_file: train.jsonl  # Generated by convert_hf_dataset.py or convert_rollouts.py
  batch_size: 4  # Smaller batch for longer sequences

model:
  path: Qwen/Qwen3-8B
  qlora_rank: 32
  name: "Distilled Assistant"
  description: "Model trained on teacher-generated completions via SFT"

trainer:
  num_epochs: 3
  learning_rate: 0.00005
  save_step: 100
  eval_step: 100
